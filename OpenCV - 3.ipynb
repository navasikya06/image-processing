{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "#Keypoint, corner, SIFT, SURF, FAST, BRIEF, ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('./images/box.png')\n",
    "\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "\n",
    "# To detect only sharp corners\n",
    "dst = cv2.cornerHarris(gray, blockSize=4, ksize=5, k=0.04)\n",
    "\n",
    "# Result is dilated for marking the corners\n",
    "dst = cv2.dilate(dst, None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image\n",
    "img[dst > 0.01*dst.max()] = [0,0,0]\n",
    "\n",
    "cv2.imshow('Harris Corners(only sharp)',img)\n",
    "\n",
    "# to detect soft corners\n",
    "dst = cv2.cornerHarris(gray, blockSize=14, ksize=5, k=0.04)\n",
    "dst = cv2.dilate(dst, None)\n",
    "img[dst > 0.01*dst.max()] = [0,0,0]\n",
    "\n",
    "cv2.imshow('Harris Corners(also soft)',img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('./images/box.png')\n",
    "\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(gray, maxCorners=12, qualityLevel=0.09,\n",
    "minDistance=50)\n",
    "corners = np.float32(corners)\n",
    "\n",
    "for item in corners:\n",
    "    x, y = item[0]\n",
    "    cv2.circle(img, (x,y), 5, 255, -1)\n",
    "\n",
    "cv2.imshow(\"Top 'k' features\", img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'SIFT_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-33897abbe566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# For version opencv < 3.0.0, use cv2.SIFT()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mkeypoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescriptors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawKeypoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'SIFT_create'"
     ]
    }
   ],
   "source": [
    "input_image = cv2.imread('images/thing.jpeg')\n",
    "gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# For version opencv < 3.0.0, use cv2.SIFT()\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "cv2.drawKeypoints(input_image, keypoints, input_image, \\\n",
    "flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('SIFT features', input_image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'xfeatures2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-49c83c77c444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# For version opencv < 3.0.0, use cv2.SURF()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msurf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSURF_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# This threshold controls the number of keypoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msurf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetHessianThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'xfeatures2d'"
     ]
    }
   ],
   "source": [
    "# For version opencv < 3.0.0, use cv2.SURF()\n",
    "surf = cv2.xfeatures2d.SURF_create()\n",
    "\n",
    "# This threshold controls the number of keypoints\n",
    "surf.setHessianThreshold(15000)\n",
    "keypoints, descriptors = surf.detectAndCompute(gray_image, None)\n",
    "cv2.drawKeypoints(input_image, keypoints, input_image, color=(0,255,0),\\\n",
    "flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('SURF features', input_image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keypoints with non max suppression: 14523\n",
      "Total Keypoints without nonmaxSuppression: 46698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image = cv2.imread('images/thing.jpeg')\n",
    "gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Version under opencv 3.0.0 cv2.FastFeatureDetector()\n",
    "fast = cv2.FastFeatureDetector_create()\n",
    "\n",
    "# Detect keypoints\n",
    "keypoints = fast.detect(gray_image, None)\n",
    "print(\"Number of keypoints with non max suppression:\", len(keypoints))\n",
    "\n",
    "# Draw keypoints on top of the input image\n",
    "img_keypoints_with_nonmax=input_image.copy()\n",
    "cv2.drawKeypoints(input_image, keypoints, img_keypoints_with_nonmax,\n",
    "                  color=(0,255,0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imshow('FAST keypoints - with non max suppression',\n",
    "           img_keypoints_with_nonmax)\n",
    "\n",
    "# Disable nonmaxSuppression\n",
    "fast.setNonmaxSuppression(False)\n",
    "# Detect keypoints again\n",
    "keypoints = fast.detect(gray_image, None)\n",
    "print(\"Total Keypoints without nonmaxSuppression:\", len(keypoints))\n",
    "\n",
    "# Draw keypoints on top of the input image\n",
    "img_keypoints_without_nonmax=input_image.copy()\n",
    "cv2.drawKeypoints(input_image, keypoints, img_keypoints_without_nonmax,\n",
    "                  color=(0,255,0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imshow('FAST keypoints - without non max suppression',\n",
    "           img_keypoints_without_nonmax)\n",
    "\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'BriefDescriptorExtractor_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-211b2f29a217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Initiate BRIEF extractor, before opencv 3.0.0 use cv2.DescriptorExtractor_create(\"BRIEF\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbrief\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBriefDescriptorExtractor_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# find the keypoints with STAR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'BriefDescriptorExtractor_create'"
     ]
    }
   ],
   "source": [
    "# Initiate FAST detector\n",
    "fast = cv2.FastFeatureDetector_create()\n",
    "\n",
    "# Initiate BRIEF extractor, before opencv 3.0.0 use cv2.DescriptorExtractor_create(\"BRIEF\")\n",
    "brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "\n",
    "# find the keypoints with STAR\n",
    "keypoints = fast.detect(gray_image, None)\n",
    "\n",
    "# compute the descriptors with BRIEF\n",
    "keypoints, descriptors = brief.compute(gray_image, keypoints)\n",
    "cv2.drawKeypoints(input_image, keypoints, input_image, color=(0,255,0))\n",
    "\n",
    "cv2.imshow('BRIEF keypoints', input_image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate ORB object, before opencv 3.0.0 use cv2.ORB()\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# find the keypoints with ORB\n",
    "keypoints = orb.detect(gray_image, None)\n",
    "\n",
    "# compute the descriptors with ORB\n",
    "keypoints, descriptors = orb.compute(gray_image, keypoints)\n",
    "\n",
    "# draw only the location of the keypoints without size or orientation\n",
    "cv2.drawKeypoints(input_image, keypoints, input_image, color=(0,255,0))\n",
    "cv2.imshow('ORB keypoints', input_image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
